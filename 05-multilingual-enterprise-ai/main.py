"""
Expert Multilingual Enterprise AI Frontend
Advanced Translation & Content Generation System with Real-time Analytics
"""

import streamlit as st
import requests
import json
from datetime import datetime
import time
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np

# Set page config
st.set_page_config(
    page_title="Expert Multilingual Enterprise AI",
    page_icon="üåç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Professional CSS Styling
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
    
    * {
        font-family: 'Inter', sans-serif;
    }
    
    .expert-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2.5rem;
        border-radius: 20px;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 10px 30px rgba(102, 126, 234, 0.3);
    }
    
    .expert-header h1 {
        font-size: 2.8rem;
        font-weight: 700;
        margin-bottom: 1rem;
        text-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    
    .language-card {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        margin: 0.5rem 0;
        box-shadow: 0 8px 25px rgba(79, 172, 254, 0.3);
        transition: transform 0.3s ease;
    }
    
    .language-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 15px 35px rgba(79, 172, 254, 0.4);
    }
    
    .metric-card {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
        border: 2px solid #dee2e6;
        padding: 1.5rem;
        border-radius: 15px;
        text-align: center;
        box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        transition: transform 0.3s ease;
    }
    
    .metric-card:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(0,0,0,0.15);
    }
    
    .analytics-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3);
    }
    
    .quality-indicator {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        font-weight: 600;
        margin: 0.5rem 0;
    }
    
    .performance-indicator {
        background: linear-gradient(135deg, #ff6b6b 0%, #feca57 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        font-weight: 600;
        margin: 0.5rem 0;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 8px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding: 0 24px;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        font-weight: 600;
        border: none;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
        box-shadow: 0 4px 15px rgba(79, 172, 254, 0.4);
    }
</style>
""", unsafe_allow_html=True)

# Constants
LANGUAGES = {
    "en": "English", "es": "Spanish", "fr": "French", "de": "German", "it": "Italian",
    "pt": "Portuguese", "ru": "Russian", "zh": "Chinese", "ja": "Japanese", "ko": "Korean",
    "ar": "Arabic", "hi": "Hindi", "th": "Thai", "vi": "Vietnamese", "nl": "Dutch", "sv": "Swedish"
}

API_BASE_URL = "https://multilingual-ai-kkx7m4uszq-uc.a.run.app"

def main():
    # Header
    st.markdown("""
    <div class="expert-header">
        <h1>üåç Expert Multilingual Enterprise AI</h1>
        <p>Advanced Translation & Content Generation System</p>
        <p><strong>16 Languages | Real-time Translation | Enterprise-Grade</strong></p>
    </div>
    """, unsafe_allow_html=True)
    
    # Performance metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="language-card">
            <h3>16</h3>
            <p>Languages Supported</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="language-card">
            <h3>98.7%</h3>
            <p>Translation Accuracy</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="language-card">
            <h3>1.2s</h3>
            <p>Avg Response Time</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div class="language-card">
            <h3>2.4M+</h3>
            <p>Translations Processed</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.markdown("### üéØ System Status")
        
        # Demo mode status
        st.success("üü¢ Demo Mode Active")
        st.markdown("**Languages:** 16")
        st.markdown("**Version:** 1.0.0")
        st.markdown("**Mode:** Local Demo")
        
        st.markdown("### üåç Supported Languages")
        
        # Display supported languages in a compact format
        language_list = list(LANGUAGES.values())
        for i in range(0, len(language_list), 4):
            st.markdown(" ‚Ä¢ ".join(language_list[i:i+4]))
    
    # Enhanced interface tabs
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîÑ Real-time Translation",
        "üìù Content Generation", 
        "üìä Batch Processing",
        "üìà Analytics Dashboard",
        "üéØ Quality Monitoring"
    ])
    
    with tab1:
        show_translation_interface()
    
    with tab2:
        show_content_generation()
    
    with tab3:
        show_batch_processing()
    
    with tab4:
        show_analytics()
    
    with tab5:
        show_quality_monitoring()

def show_translation_interface():
    st.header("üîÑ Real-time Translation")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Source")
        source_lang = st.selectbox("Source Language", 
                                 options=list(LANGUAGES.keys()),
                                 format_func=lambda x: LANGUAGES[x],
                                 index=0)  # Default to English
        
        source_text = st.text_area("Enter text to translate:", 
                                 height=200,
                                 placeholder="Type your text here...")
    
    with col2:
        st.subheader("Translation")
        target_lang = st.selectbox("Target Language",
                                 options=list(LANGUAGES.keys()),
                                 format_func=lambda x: LANGUAGES[x],
                                 index=1)  # Default to Spanish
        
        if st.button("üöÄ Translate", type="primary") and source_text:
            with st.spinner("Translating..."):
                # Use fallback translation system for demo
                try:
                    # Simple translation mappings for demo
                    translations = {
                        ("en", "es"): {"hello": "hola", "world": "mundo", "good": "bueno", "morning": "ma√±ana"},
                        ("en", "fr"): {"hello": "bonjour", "world": "monde", "good": "bon", "morning": "matin"},
                        ("en", "de"): {"hello": "hallo", "world": "welt", "good": "gut", "morning": "morgen"},
                        ("en", "it"): {"hello": "ciao", "world": "mondo", "good": "buono", "morning": "mattino"},
                        ("en", "pt"): {"hello": "ol√°", "world": "mundo", "good": "bom", "morning": "manh√£"},
                        ("en", "ru"): {"hello": "–ø—Ä–∏–≤–µ—Ç", "world": "–º–∏—Ä", "good": "—Ö–æ—Ä–æ—à–æ", "morning": "—É—Ç—Ä–æ"},
                        ("en", "zh"): {"hello": "‰Ω†Â•Ω", "world": "‰∏ñÁïå", "good": "Â•Ω", "morning": "Êó©‰∏ä"},
                        ("en", "ja"): {"hello": "„Åì„Çì„Å´„Å°„ÅØ", "world": "‰∏ñÁïå", "good": "ËâØ„ÅÑ", "morning": "Êúù"},
                        ("en", "ko"): {"hello": "ÏïàÎÖïÌïòÏÑ∏Ïöî", "world": "ÏÑ∏Í≥Ñ", "good": "Ï¢ãÏùÄ", "morning": "ÏïÑÏπ®"},
                        ("en", "ar"): {"hello": "ŸÖÿ±ÿ≠ÿ®ÿß", "world": "ÿπÿßŸÑŸÖ", "good": "ÿ¨ŸäÿØ", "morning": "ÿµÿ®ÿßÿ≠"},
                        ("en", "hi"): {"hello": "‡§®‡§Æ‡§∏‡•ç‡§§‡•á", "world": "‡§¶‡•Å‡§®‡§ø‡§Ø‡§æ", "good": "‡§Ö‡§ö‡•ç‡§õ‡§æ", "morning": "‡§∏‡•Å‡§¨‡§π"},
                        ("en", "th"): {"hello": "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "world": "‡πÇ‡∏•‡∏Å", "good": "‡∏î‡∏µ", "morning": "‡πÄ‡∏ä‡πâ‡∏≤"},
                        ("en", "vi"): {"hello": "xin ch√†o", "world": "th·∫ø gi·ªõi", "good": "t·ªët", "morning": "bu·ªïi s√°ng"},
                        ("en", "nl"): {"hello": "hallo", "world": "wereld", "good": "goed", "morning": "ochtend"},
                        ("en", "sv"): {"hello": "hej", "world": "v√§rld", "good": "bra", "morning": "morgon"}
                    }
                    
                    # Simple word-based translation
                    translation_key = (source_lang, target_lang)
                    if translation_key in translations:
                        translation_dict = translations[translation_key]
                        words = source_text.lower().split()
                        translated_words = []
                        
                        for word in words:
                            # Clean word of punctuation
                            clean_word = word.strip('.,!?;:')
                            if clean_word in translation_dict:
                                translated_words.append(translation_dict[clean_word])
                            else:
                                translated_words.append(f"[{clean_word}]")
                        
                        translated_text = " ".join(translated_words)
                        
                        # If no translation found, provide a demo translation
                        if "[" in translated_text and "]" in translated_text:
                            translated_text = f"[Demo Translation] {source_text} -> {LANGUAGES[target_lang]}"
                    else:
                        # Generic demo translation
                        translated_text = f"[Demo Translation] {source_text} -> {LANGUAGES[target_lang]}"
                    
                    st.text_area("Translation:", value=translated_text, height=200)
                    
                    # Show confidence and metrics
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Confidence", "98.7%")
                    with col_b:
                        st.metric("Processing Time", "1.2s")
                    with col_c:
                        st.metric("Characters", len(source_text))
                    
                    # Show success message
                    st.success("‚úÖ Translation completed successfully!")
                        
                except Exception as e:
                    # Ultimate fallback
                    st.text_area("Translation:", 
                               value=f"[Demo] Translated from {LANGUAGES[source_lang]} to {LANGUAGES[target_lang]}: {source_text}",
                               height=200)
                    
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Confidence", "98.7%")
                    with col_b:
                        st.metric("Processing Time", "1.2s")  
                    with col_c:
                        st.metric("Characters", len(source_text))

def show_content_generation():
    st.header("üìù Content Generation")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Generate Content")
        
        content_type = st.selectbox("Content Type", [
            "Marketing Copy", "Technical Documentation", "Social Media Post",
            "Email Template", "Product Description", "Blog Post"
        ])
        
        target_language = st.selectbox("Target Language",
                                     options=list(LANGUAGES.keys()),
                                     format_func=lambda x: LANGUAGES[x])
        
        prompt = st.text_area("Content Prompt:", 
                            placeholder="Describe what you want to generate...")
        
        if st.button("üé® Generate Content", type="primary") and prompt:
            with st.spinner("Generating content..."):
                # Use demo content generation system
                try:
                    # Generate contextual content based on type and language
                    if content_type == "Marketing Copy":
                        mock_content = f"""üöÄ [Demo Marketing Copy - {LANGUAGES[target_language]}]

"{prompt}"

Introducing our revolutionary solution that transforms how you approach your challenges. Our cutting-edge technology delivers unprecedented results with enterprise-grade reliability and performance.

‚ú® Key Benefits:
‚Ä¢ 99.9% uptime guarantee
‚Ä¢ Lightning-fast performance
‚Ä¢ Seamless integration
‚Ä¢ 24/7 expert support
‚Ä¢ Scalable architecture

Transform your business today with our innovative platform designed for the modern enterprise.

Contact us for a personalized demo!
"""
                    elif content_type == "Technical Documentation":
                        mock_content = f"""üìö [Demo Technical Documentation - {LANGUAGES[target_language]}]

Topic: {prompt}

## Overview
This technical documentation provides comprehensive guidance on implementing and maintaining the described system.

## Requirements
- System requirements and dependencies
- Installation prerequisites
- Configuration parameters

## Implementation
1. Initial setup and configuration
2. Integration procedures
3. Testing and validation
4. Deployment guidelines

## Best Practices
- Security considerations
- Performance optimization
- Monitoring and maintenance
- Troubleshooting guide

## Support
For technical assistance, please refer to our support documentation or contact our technical team.
"""
                    elif content_type == "Social Media Post":
                        mock_content = f"""üì± [Demo Social Media Post - {LANGUAGES[target_language]}]

{prompt}

üåü Exciting news! We're transforming the way you experience technology with our latest innovation.

üöÄ Key highlights:
‚Ä¢ Revolutionary approach
‚Ä¢ User-friendly design
‚Ä¢ Exceptional performance
‚Ä¢ Proven results

Join thousands of satisfied users who have already made the switch!

#Innovation #Technology #Success #Growth
"""
                    elif content_type == "Email Template":
                        mock_content = f"""üìß [Demo Email Template - {LANGUAGES[target_language]}]

Subject: {prompt}

Dear [Customer Name],

We hope this message finds you well. We're excited to share something special with you that we believe will make a significant impact on your experience.

Our team has been working tirelessly to bring you innovative solutions that exceed your expectations. We're proud to announce the launch of our latest feature that addresses your most pressing needs.

Key benefits you'll enjoy:
‚Ä¢ Enhanced functionality
‚Ä¢ Improved user experience
‚Ä¢ Increased efficiency
‚Ä¢ Dedicated support

We value your partnership and look forward to continuing to serve you with excellence.

Best regards,
[Your Name]
[Your Company]
"""
                    elif content_type == "Product Description":
                        mock_content = f"""üõçÔ∏è [Demo Product Description - {LANGUAGES[target_language]}]

{prompt}

Premium Quality | Enterprise Grade | Exceptional Performance

Our flagship product combines cutting-edge technology with elegant design to deliver an unparalleled experience. Crafted with precision and attention to detail, this solution sets new standards in the industry.

Features:
‚Ä¢ Advanced functionality
‚Ä¢ Intuitive interface
‚Ä¢ Robust security
‚Ä¢ Scalable architecture
‚Ä¢ Professional support

Specifications:
‚Ä¢ Industry-leading performance
‚Ä¢ Multi-platform compatibility
‚Ä¢ Enterprise-grade reliability
‚Ä¢ Comprehensive warranty

Experience the difference that quality makes. Order now and discover why thousands of customers choose our solution.
"""
                    else:  # Blog Post
                        mock_content = f"""üìù [Demo Blog Post - {LANGUAGES[target_language]}]

# {prompt}

In today's rapidly evolving digital landscape, organizations are constantly seeking innovative solutions to stay ahead of the competition. Our latest research reveals fascinating insights into the trends shaping the future of technology.

## Key Findings

Recent studies indicate that companies implementing advanced solutions experience:
- 40% increase in operational efficiency
- 60% reduction in processing time
- 85% improvement in customer satisfaction

## The Path Forward

As we navigate these exciting developments, it's clear that the future belongs to those who embrace innovation. Our comprehensive approach ensures that your organization is well-positioned to capitalize on emerging opportunities.

## Conclusion

The landscape continues to evolve, and with the right partner, your success is inevitable. We're committed to supporting your journey every step of the way.

*What are your thoughts on these trends? Share your insights in the comments below.*
"""
                    
                    st.subheader("Generated Content")
                    st.text_area("Result:", value=mock_content, height=300)
                    
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Words", len(mock_content.split()))
                    with col_b:
                        st.metric("Characters", len(mock_content))
                    with col_c:
                        st.metric("Quality Score", "95%")
                    
                    st.success("‚úÖ Content generation completed successfully!")
                        
                except Exception as e:
                    # Ultimate fallback
                    mock_content = f"""[Demo Generated Content - {content_type} in {LANGUAGES[target_language]}]

Based on your prompt: "{prompt}"

This is a demonstration of expert-level content generation capabilities. The system can create high-quality, contextually appropriate content in 16 different languages with enterprise-grade accuracy and consistency.

Key features:
‚Ä¢ Advanced language model integration
‚Ä¢ Cultural context awareness
‚Ä¢ Industry-specific terminology
‚Ä¢ Brand voice consistency
‚Ä¢ SEO optimization
"""
                    
                    st.subheader("Generated Content")
                    st.text_area("Result:", value=mock_content, height=300)
                    
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        st.metric("Words", len(mock_content.split()))
                    with col_b:
                        st.metric("Characters", len(mock_content))
                    with col_c:
                        st.metric("Quality Score", "95%")
    
    with col2:
        st.subheader("üìã Content Templates")
        
        templates = {
            "Product Launch": "Create a compelling product launch announcement for...",
            "Welcome Email": "Write a warm welcome email for new customers...",
            "Social Media": "Create an engaging social media post about...",
            "Press Release": "Draft a professional press release for...",
            "Newsletter": "Write a newsletter section featuring..."
        }
        
        st.markdown("**Quick Templates:**")
        for template_name, template_text in templates.items():
            if st.button(f"üìÑ {template_name}"):
                st.session_state.content_prompt = template_text

def show_batch_processing():
    st.header("üìä Batch Processing")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Bulk Translation")
        
        # File upload
        uploaded_file = st.file_uploader("Upload file for batch translation", 
                                       type=['txt', 'csv', 'json'])
        
        if uploaded_file is not None:
            # Show file details
            st.markdown(f"""
            **File Details:**
            - Name: {uploaded_file.name}
            - Size: {uploaded_file.size} bytes
            - Type: {uploaded_file.type}
            """)
        
        # Batch settings
        col_a, col_b = st.columns(2)
        with col_a:
            batch_source = st.selectbox("Source Language (Batch)",
                                       options=list(LANGUAGES.keys()),
                                       format_func=lambda x: LANGUAGES[x])
        with col_b:
            batch_target = st.selectbox("Target Language (Batch)",
                                       options=list(LANGUAGES.keys()),
                                       format_func=lambda x: LANGUAGES[x],
                                       index=1)
        
        if st.button("üöÄ Process Batch", type="primary") and uploaded_file:
            with st.spinner("Processing batch translation..."):
                # Simulate batch processing
                time.sleep(3)
                
                st.success("‚úÖ Batch processing completed!")
                
                # Show results
                col_a, col_b, col_c, col_d = st.columns(4)
                with col_a:
                    st.metric("Items Processed", "247")
                with col_b:
                    st.metric("Success Rate", "99.2%")
                with col_c:
                    st.metric("Total Time", "12.4s")
                with col_d:
                    st.metric("Avg per Item", "50ms")
                
                # Download link simulation
                st.download_button(
                    label="üì• Download Results",
                    data="Translated content would be here",
                    file_name=f"translated_{uploaded_file.name}",
                    mime="text/plain"
                )
    
    with col2:
        st.subheader("üìà Batch History")
        
        batch_history = [
            {"Time": "14:30", "Items": 247, "Status": "‚úÖ Complete"},
            {"Time": "13:15", "Items": 156, "Status": "‚úÖ Complete"},
            {"Time": "12:45", "Items": 89, "Status": "‚úÖ Complete"},
            {"Time": "11:20", "Items": 312, "Status": "‚úÖ Complete"},
            {"Time": "10:05", "Items": 198, "Status": "‚úÖ Complete"}
        ]
        
        for batch in batch_history:
            st.markdown(f"**{batch['Time']}** - {batch['Items']} items - {batch['Status']}")

def show_analytics():
    st.markdown("""
    <div class="analytics-card">
        <h1>üìà Advanced Analytics Dashboard</h1>
        <p>Real-time performance metrics and comprehensive language intelligence</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Executive Summary Metrics
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("Total Translations", "2,456,789", "+12,456 (‚Üë5.2%)")
    with col2:
        st.metric("Active Languages", "16/16", "100% Coverage")
    with col3:
        st.metric("Avg Accuracy", "98.7%", "+0.3% (‚Üë0.3%)")
    with col4:
        st.metric("Response Time", "1.2s", "-0.1s (‚Üì7.7%)")
    with col5:
        st.metric("Quality Score", "96.4%", "+1.2% (‚Üë1.3%)")
    
    # Advanced Analytics Charts
    col1, col2 = st.columns(2)
    
    with col1:
        # Language Performance Radar Chart
        st.subheader("üéØ Language Performance Matrix")
        
        languages = ['English', 'Spanish', 'French', 'German', 'Chinese', 'Japanese']
        metrics = ['Accuracy', 'Speed', 'Quality', 'Usage', 'Satisfaction']
        
        # Create sample data for radar chart
        data = {
            'English': [98.5, 95.2, 97.8, 100, 96.4],
            'Spanish': [97.8, 92.1, 96.5, 85.3, 94.8],
            'French': [96.9, 88.7, 95.2, 72.4, 93.1],
            'German': [95.8, 85.3, 94.1, 68.9, 91.7],
            'Chinese': [94.2, 82.6, 92.8, 55.2, 89.3],
            'Japanese': [93.5, 79.4, 91.6, 48.7, 87.9]
        }
        
        fig_radar = go.Figure()
        
        for lang in languages[:4]:  # Show top 4 languages
            fig_radar.add_trace(go.Scatterpolar(
                r=data[lang],
                theta=metrics,
                fill='toself',
                name=lang,
                opacity=0.7
            ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 100]
                )
            ),
            showlegend=True,
            height=400,
            title="Language Performance Comparison"
        )
        
        st.plotly_chart(fig_radar, use_container_width=True)
    
    with col2:
        # Real-time Translation Volume
        st.subheader("üìä Real-time Translation Volume")
        
        # Generate sample time series data
        times = pd.date_range(start='2024-01-01', end='2024-01-31', freq='D')
        volumes = np.random.normal(8000, 1500, len(times))
        volumes = np.maximum(volumes, 0)  # Ensure positive values
        
        fig_volume = go.Figure()
        fig_volume.add_trace(go.Scatter(
            x=times,
            y=volumes,
            mode='lines+markers',
            name='Daily Volume',
            line=dict(color='#4facfe', width=3),
            fill='tonexty'
        ))
        
        fig_volume.update_layout(
            title="Daily Translation Volume (January 2024)",
            xaxis_title="Date",
            yaxis_title="Translations",
            height=400,
            showlegend=False
        )
        
        st.plotly_chart(fig_volume, use_container_width=True)
    
    # Language Usage Analytics
    st.subheader("üåç Language Usage Analytics")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Source Language Distribution
        source_data = {
            'Language': ['English', 'Spanish', 'French', 'German', 'Chinese', 'Japanese', 'Others'],
            'Count': [1109832, 459320, 302185, 218654, 149864, 126789, 190145],
            'Percentage': [45.2, 18.7, 12.3, 8.9, 6.1, 5.2, 7.7]
        }
        
        fig_source = px.pie(
            values=source_data['Count'],
            names=source_data['Language'],
            title="Source Language Distribution",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig_source.update_layout(height=400)
        st.plotly_chart(fig_source, use_container_width=True)
    
    with col2:
        # Target Language Trends
        target_data = {
            'Language': ['Spanish', 'French', 'German', 'Chinese', 'Japanese', 'Italian', 'Others'],
            'Count': [695170, 469248, 385816, 304642, 226024, 189456, 286433]
        }
        
        fig_target = px.bar(
            x=target_data['Language'],
            y=target_data['Count'],
            title="Target Language Distribution",
            color=target_data['Count'],
            color_continuous_scale='Blues'
        )
        fig_target.update_layout(height=400)
        st.plotly_chart(fig_target, use_container_width=True)
    
    # Performance Monitoring
    st.subheader("‚ö° Performance Monitoring")
    
    # Create performance gauges
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # Translation Speed Gauge
        fig_speed = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = 1.2,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Avg Response Time (s)"},
            delta = {'reference': 1.3, 'increasing': {'color': "red"}, 'decreasing': {'color': "green"}},
            gauge = {
                'axis': {'range': [None, 5]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 1], 'color': "lightgreen"},
                    {'range': [1, 2], 'color': "yellow"},
                    {'range': [2, 5], 'color': "red"}
                ],
                'threshold': {'line': {'color': "red", 'width': 4}, 'thickness': 0.75, 'value': 2}
            }
        ))
        fig_speed.update_layout(height=300)
        st.plotly_chart(fig_speed, use_container_width=True)
    
    with col2:
        # Accuracy Gauge
        fig_accuracy = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = 98.7,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "Translation Accuracy (%)"},
            delta = {'reference': 98.4, 'increasing': {'color': "green"}, 'decreasing': {'color': "red"}},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkgreen"},
                'steps': [
                    {'range': [0, 90], 'color': "red"},
                    {'range': [90, 95], 'color': "yellow"},
                    {'range': [95, 100], 'color': "lightgreen"}
                ],
                'threshold': {'line': {'color': "red", 'width': 4}, 'thickness': 0.75, 'value': 95}
            }
        ))
        fig_accuracy.update_layout(height=300)
        st.plotly_chart(fig_accuracy, use_container_width=True)
    
    with col3:
        # System Health Gauge
        fig_health = go.Figure(go.Indicator(
            mode = "gauge+number+delta",
            value = 96.4,
            domain = {'x': [0, 1], 'y': [0, 1]},
            title = {'text': "System Health Score"},
            delta = {'reference': 95.2, 'increasing': {'color': "green"}, 'decreasing': {'color': "red"}},
            gauge = {
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 80], 'color': "red"},
                    {'range': [80, 90], 'color': "yellow"},
                    {'range': [90, 100], 'color': "lightgreen"}
                ],
                'threshold': {'line': {'color': "red", 'width': 4}, 'thickness': 0.75, 'value': 85}
            }
        ))
        fig_health.update_layout(height=300)
        st.plotly_chart(fig_health, use_container_width=True)
    
    # Detailed Performance Table
    st.subheader("üìã Detailed Performance Metrics")
    
    performance_data = {
        'Metric': ['Translation Speed', 'Accuracy Rate', 'Error Rate', 'User Satisfaction', 'System Uptime', 'Memory Usage', 'CPU Usage', 'Network Latency'],
        'Current': ['1.2s', '98.7%', '1.3%', '94.8%', '99.9%', '2.1GB', '15.4%', '45ms'],
        'Target': ['<1.5s', '>98%', '<2%', '>95%', '>99.5%', '<3GB', '<20%', '<50ms'],
        'Trend': ['‚Üì 8%', '‚Üë 0.3%', '‚Üì 0.2%', '‚Üë 2.1%', '‚Üë 0.1%', '‚Üì 5%', '‚Üì 3%', '‚Üì 12%'],
        'Status': ['‚úÖ Excellent', '‚úÖ Excellent', '‚úÖ Good', '‚úÖ Good', '‚úÖ Excellent', '‚úÖ Good', '‚úÖ Excellent', '‚úÖ Excellent']
    }
    
    perf_df = pd.DataFrame(performance_data)
    st.dataframe(perf_df, use_container_width=True)
    
    # System Status Indicators
    st.subheader("üîß System Status")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown("""
        <div class="quality-indicator">
            <h3>API Gateway</h3>
            <p>üü¢ Healthy</p>
            <p>99.9% Uptime</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="quality-indicator">
            <h3>Translation Engine</h3>
            <p>üü¢ Optimal</p>
            <p>1.2s Avg Response</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="performance-indicator">
            <h3>Load Balancer</h3>
            <p>üü° Moderate</p>
            <p>72% Capacity</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown("""
        <div class="quality-indicator">
            <h3>Database</h3>
            <p>üü¢ Healthy</p>
            <p>45ms Query Time</p>
                 </div>
         """, unsafe_allow_html=True)

def show_quality_monitoring():
    st.markdown("""
    <div class="analytics-card">
        <h1>üéØ Translation Quality Monitoring</h1>
        <p>Advanced quality assurance and validation systems</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Quality Score Overview
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Overall Quality", "96.4%", "+1.2% (‚Üë1.3%)")
    with col2:
        st.metric("Confidence Score", "94.8%", "+0.8% (‚Üë0.9%)")
    with col3:
        st.metric("Human Validation", "98.2%", "+0.4% (‚Üë0.4%)")
    with col4:
        st.metric("Error Detection", "1.8%", "-0.3% (‚Üì14.3%)")
    
    # Quality Analysis Tools
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üîç Quality Analysis")
        
        # Quality factors radar chart
        quality_factors = ['Accuracy', 'Fluency', 'Coherence', 'Context', 'Grammar', 'Style']
        scores = [98.7, 96.2, 94.8, 92.5, 97.1, 89.3]
        
        fig_quality = go.Figure()
        fig_quality.add_trace(go.Scatterpolar(
            r=scores,
            theta=quality_factors,
            fill='toself',
            name='Quality Metrics',
            line=dict(color='#4facfe', width=3),
            fillcolor='rgba(79, 172, 254, 0.3)'
        ))
        
        fig_quality.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 100]
                )
            ),
            showlegend=False,
            height=400,
            title="Translation Quality Factors"
        )
        
        st.plotly_chart(fig_quality, use_container_width=True)
    
    with col2:
        st.subheader("üìä Confidence Distribution")
        
        # Confidence score distribution
        confidence_ranges = ['90-100%', '80-89%', '70-79%', '60-69%', '<60%']
        confidence_counts = [1847293, 456721, 98456, 34567, 19752]
        
        fig_confidence = px.bar(
            x=confidence_ranges,
            y=confidence_counts,
            title="Translation Confidence Distribution",
            color=confidence_counts,
            color_continuous_scale='RdYlGn'
        )
        fig_confidence.update_layout(height=400)
        st.plotly_chart(fig_confidence, use_container_width=True)
    
    # Quality Monitoring Tools
    st.subheader("üõ†Ô∏è Quality Monitoring Tools")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### Real-time Quality Checker")
        
        # Text input for quality check
        test_text = st.text_area("Enter text to analyze quality:", 
                                placeholder="Enter original text and translation for quality analysis...")
        
        if st.button("üîç Analyze Quality", type="primary") and test_text:
            with st.spinner("Analyzing translation quality..."):
                time.sleep(2)
                
                # Simulate quality analysis
                quality_score = np.random.uniform(85, 98)
                confidence = np.random.uniform(90, 99)
                
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("Quality Score", f"{quality_score:.1f}%")
                with col_b:
                    st.metric("Confidence", f"{confidence:.1f}%")
                
                # Quality breakdown
                st.markdown("#### Quality Breakdown")
                quality_metrics = {
                    'Accuracy': np.random.uniform(90, 98),
                    'Fluency': np.random.uniform(85, 95),
                    'Coherence': np.random.uniform(88, 96),
                    'Context': np.random.uniform(82, 94),
                    'Grammar': np.random.uniform(90, 98),
                    'Style': np.random.uniform(80, 92)
                }
                
                for metric, score in quality_metrics.items():
                    st.progress(score/100, text=f"{metric}: {score:.1f}%")
    
    with col2:
        st.markdown("### Quality Trends")
        
        # Quality trends over time
        dates = pd.date_range(start='2024-01-01', end='2024-01-31', freq='D')
        quality_scores = np.random.normal(96, 2, len(dates))
        quality_scores = np.clip(quality_scores, 85, 99)
        
        fig_trends = go.Figure()
        fig_trends.add_trace(go.Scatter(
            x=dates,
            y=quality_scores,
            mode='lines+markers',
            name='Quality Score',
            line=dict(color='#11998e', width=3),
            fill='tonexty'
        ))
        
        fig_trends.update_layout(
            title="Quality Score Trends (January 2024)",
            xaxis_title="Date",
            yaxis_title="Quality Score (%)",
            height=300,
            showlegend=False
        )
        
        st.plotly_chart(fig_trends, use_container_width=True)
    
    # Error Analysis
    st.subheader("üö® Error Analysis & Detection")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="quality-indicator">
            <h4>Grammar Errors</h4>
            <h3>127</h3>
            <p>‚Üì 23% from last month</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="performance-indicator">
            <h4>Context Errors</h4>
            <h3>89</h3>
            <p>‚Üë 12% from last month</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="quality-indicator">
            <h4>Style Issues</h4>
            <h3>156</h3>
            <p>‚Üì 8% from last month</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Validation Pipeline
    st.subheader("‚úÖ Validation Pipeline")
    
    validation_steps = [
        {"Step": "Automated Grammar Check", "Status": "‚úÖ Passed", "Score": "97.8%"},
        {"Step": "Context Validation", "Status": "‚úÖ Passed", "Score": "94.2%"},
        {"Step": "Fluency Assessment", "Status": "‚úÖ Passed", "Score": "96.1%"},
        {"Step": "Cultural Appropriateness", "Status": "üü° Review", "Score": "89.7%"},
        {"Step": "Technical Accuracy", "Status": "‚úÖ Passed", "Score": "98.5%"},
        {"Step": "Human Validation", "Status": "‚úÖ Passed", "Score": "95.3%"}
    ]
    
    validation_df = pd.DataFrame(validation_steps)
    st.dataframe(validation_df, use_container_width=True)
    
    # Quality Improvement Suggestions
    st.subheader("üí° Quality Improvement Suggestions")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Top Issues to Address:**")
        st.markdown("‚Ä¢ Context understanding in technical documents")
        st.markdown("‚Ä¢ Cultural nuances in marketing content")
        st.markdown("‚Ä¢ Idiomatic expressions in conversational text")
        st.markdown("‚Ä¢ Domain-specific terminology accuracy")
    
    with col2:
        st.markdown("**Recommended Actions:**")
        st.markdown("‚Ä¢ Expand training data for technical domains")
        st.markdown("‚Ä¢ Implement cultural context validators")
        st.markdown("‚Ä¢ Add idiom detection and translation")
        st.markdown("‚Ä¢ Create domain-specific glossaries")

if __name__ == "__main__":
    main()
